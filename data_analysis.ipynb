{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (16, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "  table {margin-left: 0 !important;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of the data structure: \n",
    "Our main dataset [Dunnhumby - The complete journey](https://www.dunnhumby.com/careers/engineering/sourcefiles) comprises 8 csv files with the following tabular structure and content.\n",
    "\n",
    "#### Campaign Desc\n",
    "> This table gives the length of time for which a campaign runs. So, any coupons received as part of a campaign are valid within the dates contained in this table.\n",
    "\n",
    "Description | Campaign ID | Start and End Day\n",
    "--- | --- | ---\n",
    "{TypeA, TypeB, TypeC} | int | int (probably day count from study)\n",
    "\n",
    "\n",
    "#### Campaign Table\n",
    "> This table lists the campaigns received by each household in the study. Each household received a different set of campaigns.\n",
    "\n",
    "Description | Campaign ID | Household key\n",
    "--- | --- | ---\n",
    "{TypeA, TypeB, TypeC} | int | int\n",
    "\n",
    "\n",
    "#### Casual Data\n",
    "> This table signifies whether a given product was featured in the weekly mailer or was part of an in-store display (other than regular product placement).\n",
    "\n",
    "Product ID | Store ID | Week | Display location | Mailer location\n",
    "--- | --- | --- | --- | --- \n",
    "int | int | int | int | String\n",
    " | | | Advertisement in in-store display? | Featured as ad in weekly mailer\n",
    " \n",
    " \n",
    "#### Coupon Redemption\n",
    "Household ID | Day | Coupon ID | Campaign ID \n",
    "--- | --- | --- | --- \n",
    "int | int | int | int \n",
    "\n",
    "\n",
    "#### Coupon\n",
    "> This table lists all the coupons sent to customers as part of a campaign, as well as the products for which each coupon is redeemable. Some coupons are redeemable for multiple products. \n",
    "\n",
    "Coupon ID | Product ID | Campaign ID \n",
    "--- | --- | ---  \n",
    "int | int | int \n",
    "\n",
    "\n",
    "#### Demographic\n",
    "> This table contains demographic information for a portion of households. Due to nature of the data, the demographic information is not available for all households.\n",
    "\n",
    "Age | Marital Status Code | Income | Homeowner | Household composition | Household size | Number of kids | Household Id\n",
    "--- | --- | --- | --- | --- | --- | --- | --- |\n",
    "(19-65+) | {A: Married, B: Single, U: Unknown} | | {Homeowner, Retired, etc.} | {Female/Male single, adults with/without kids, etc.} || (1-3+) |\n",
    "\n",
    "\n",
    "#### Products\n",
    "Product Id | Manufacturer Id | Departement  | Brand | Commodity description | Sub commodity description | Size\n",
    "--- | --- | --- | --- | --- | --- | --- \n",
    " | | {grocery, pastry, etc.} | {national/private} | | |\n",
    " \n",
    " \n",
    "### Transaction\n",
    "> This table contains all products purchased by households within this study. Each line found in this table is essentially the same line that would be found on a store receipt.\n",
    "\n",
    "Household Id | Manufacturer Id | Week | Day | Time of Day | Product Id | Quantity | Sales value | Store Id | Retail discount | Coupon discount | Coupon match discount\n",
    "--- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | \n",
    " | | | | | | | What the shop actually gets | | | Loyalty program of retailer | Shop does not get price before discount | Shop does get price before discount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading the data in pandas dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Campaign description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_campaign_desc = pd.read_csv('dunnhumby/campaign_desc.csv')\n",
    "df_campaign_desc.columns = map(str.lower, df_campaign_desc.columns)\n",
    "print(df_campaign_desc.shape)\n",
    "df_campaign_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of campaigns: {} '.format(len(df_campaign_desc.campaign)))\n",
    "print('Unique description values: {} '.format(df_campaign_desc.description.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add duration column to dataframe\n",
    "df_campaign_desc['duration'] = df_campaign_desc['end_day'] - df_campaign_desc['start_day'] \n",
    "df_campaign_desc.sort_values(by = ['description', 'duration']).reset_index(drop=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the longest campaign was on for 40 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for camp in ['TypeA', 'TypeB', 'TypeC']:\n",
    "    print('Campaigns of %s range between %d and %d days' %(camp, df_campaign_desc[df_campaign_desc.description == camp].duration.min(),\n",
    "                                                     df_campaign_desc[df_campaign_desc.description == camp].duration.max()))\n",
    "    print('with a mean duration of %.2f days and a median duration of %.2f days. \\n' \n",
    "            %(df_campaign_desc[df_campaign_desc.description == camp].duration.mean(),\n",
    "              df_campaign_desc[df_campaign_desc.description == camp].duration.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Campaign table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_campaign_table = pd.read_csv('dunnhumby/campaign_table.csv')\n",
    "df_campaign_table.columns = map(str.lower, df_campaign_table.columns)\n",
    "print(df_campaign_table.shape)\n",
    "df_campaign_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since both campaign tables (one containing the data and the other providing further descriptions regarding each campaign) have one \"key\" in common, namely the `campaign id` we can join (full outer join) these two tables in order to have all information in one place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_campaign_full = pd.merge(df_campaign_desc, df_campaign_table, on='campaign', how='outer').rename(columns={\"descritpion_x\": \"description\"}).drop(columns='description_y')\n",
    "# Map the lowering function to all column names\n",
    "df_campaign_full.columns = map(str.lower, df_campaign_full.columns)\n",
    "df_campaign_full.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distributional analysis of how campaigns reached each household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = df_campaign_table.groupby(by = 'household_key').campaign.count().max()\n",
    "df_campaign_table.groupby(by = 'household_key').campaign.count().hist(bins = nbins)\n",
    "plt.title('Distribution of how many households have benefitted from how many campaigns')\n",
    "plt.xlabel('Number of campaigns')\n",
    "plt.ylabel('Number of households')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above plot we can see, that most households have only benefited from 1 campaign and very few have made use of more than 10 campaigns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_campaign_full.groupby(by = 'household_key').campaign.count().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Mean number of campaigns:_ ~4.55\n",
    "\n",
    "_Max number of campaigns:_ 17\n",
    "\n",
    "_Looking at the quantiles:_\n",
    "\n",
    "* 25% of the households have made use of 2 campaigns or less. \n",
    "* 75% of the households have made use of 6 campaigns or less.\n",
    "* 95% of the households have made use of 10 campaigns or less."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many campaigns we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of campaign: ', len(df_campaign_desc.campaign))\n",
    "print('Unique description: ', df_campaign_desc.description.sort_values().unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the different campaigns over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the datas per campaign type for better visualization\n",
    "beginA = df_campaign_desc[df_campaign_desc.description == 'TypeA']['start_day'].values\n",
    "endA =   df_campaign_desc[df_campaign_desc.description == 'TypeA']['end_day'].values\n",
    "beginB = df_campaign_desc[df_campaign_desc.description == 'TypeB']['start_day'].values\n",
    "endB =   df_campaign_desc[df_campaign_desc.description == 'TypeB']['end_day'].values\n",
    "beginC = df_campaign_desc[df_campaign_desc.description == 'TypeC']['start_day'].values\n",
    "endC =   df_campaign_desc[df_campaign_desc.description == 'TypeC']['end_day'].values\n",
    "\n",
    "#Plot the timespan of each campaign (note the +1 to match the indexes starting at 0 with the campaign numbers starting at 1)\n",
    "plt.barh(df_campaign_desc[df_campaign_desc.description == 'TypeA'].index.values + 1,  endA-beginA, left=beginA, \n",
    "         color = 'red', label = 'TypeA')\n",
    "plt.barh(df_campaign_desc[df_campaign_desc.description == 'TypeB'].index.values + 1,  endB-beginB, left=beginB, \n",
    "         color = 'blue', label = 'TypeB')\n",
    "plt.barh(df_campaign_desc[df_campaign_desc.description == 'TypeC'].index.values + 1,  endC-beginC, left=beginC, \n",
    "         color = 'green', label = 'TypeC')\n",
    "\n",
    "#Add title & legend\n",
    "plt.title('Timespan of each campaign')\n",
    "plt.ylabel('Campaign')\n",
    "plt.yticks(df_campaign_desc.index + 1)\n",
    "plt.xlabel('Time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_causal = pd.read_csv('dunnhumby/causal_data.csv')\n",
    "df_causal.columns = map(str.lower, df_causal.columns)\n",
    "df_causal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coupon redemption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coupon_redempt = pd.read_csv('dunnhumby/coupon_redempt.csv')\n",
    "df_coupon_redempt.columns = map(str.lower, df_coupon_redempt.columns)\n",
    "df_coupon_redempt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coupon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coupon = pd.read_csv('dunnhumby/coupon.csv')\n",
    "df_coupon.columns = map(str.lower, df_coupon.columns)\n",
    "df_coupon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's study how many coupons were redeemed for each campaign:\n",
    "we start by adding a column stating if a coupon has been redeemed or not. `coupon_upc` here is the unique identifier of each coupon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coupon['redeemed'] = df_coupon['coupon_upc'].isin(df_coupon_redempt['coupon_upc'])\n",
    "df_coupon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coupon.redeemed[df_coupon.redeemed == True].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of coupons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_redempt_coupons = df_coupon.redeemed[df_coupon.redeemed == True].shape[0]\n",
    "redemption_rate = num_redempt_coupons / df_coupon.shape[0] * 100\n",
    "print(\"{} of {} coupons in total were actually redeemed, which corresponds to a redemption rate of {} %.\".format(num_redempt_coupons,df_coupon.shape[0], round(redemption_rate,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above rate is suprisingly high...\n",
    "\n",
    "So let us have a look how many coupons were distributed within the course of each campaign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coupon.groupby(by = 'campaign').count().plot.bar(y = 'coupon_upc')\n",
    "plt.xlabel('Campaign')\n",
    "plt.ylabel('Number of coupons')\n",
    "plt.title('Number of coupons per campaign')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice there are definetely some campaigns with way more coupons than others. Is this related to the type of campaign?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amount of coupons per campaign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now move to more advanced analysis. Let's start by combining this data with the coupon data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_campaign_desc.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_campaign_desc.sort_values(by = 'campaign', inplace = True)\n",
    "df_campaign_desc.set_index(keys = 'campaign', drop = True, inplace = True)\n",
    "df_campaign_desc['distributed'] = df_coupon.groupby(by = 'campaign').redeemed.count() #Number of coupons distributed\n",
    "df_campaign_desc['redeemed'] = df_coupon[~df_coupon['redeemed']].groupby(by = 'campaign').redeemed.count() #Number of coupons redeemed\n",
    "df_campaign_desc.fillna(0, inplace = True) \n",
    "df_campaign_desc['beneficiary'] = df_campaign_table.groupby(by = 'campaign').description.count() #Number of beneficiary households\n",
    "df_campaign_desc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's observe these results in a bar plot. For each campaign we plot the amount of coupon distributed and redeemed, and we add the type of the campaign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set width of bar\n",
    "barWidth = 0.4\n",
    " \n",
    "# set height of bar\n",
    "coupon_distributed = df_campaign_desc['distributed']\n",
    "coupon_redeemed = df_campaign_desc['redeemed']\n",
    " \n",
    "# Set position of bar on X axis\n",
    "r = np.arange(len(coupon_distributed)+1)\n",
    "r1 = [x - barWidth/2 for x in r[1:]]\n",
    "r2 = [x + barWidth/2 for x in r[1:]]\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(r1, coupon_distributed, width=barWidth, edgecolor='white', label='Distributed coupons')\n",
    "plt.bar(r2, coupon_redeemed, width=barWidth, edgecolor='white', label='Redeemed coupons')\n",
    "plt.yscale('log') #Better visualizations because very different amounts of coupon between campaign\n",
    " \n",
    "# Attach a text label above each bar in *bars*, displaying the campaign type\n",
    "type_c = df_campaign_desc.description.values\n",
    "for i in range(len(coupon_distributed.values)):    \n",
    "    plt.annotate('{}'.format(type_c[i]),\n",
    "                xy=(r[i+1], coupon_distributed.values[i]),\n",
    "                xytext=(0, 3),  # 3 points vertical offset\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom',\n",
    "                fontweight = 'bold',\n",
    "                fontsize = 8)\n",
    "  \n",
    "    \n",
    "# Add title and legend\n",
    "plt.title('Amount of coupons per campaign')\n",
    "plt.xlabel('Campaign')\n",
    "plt.xticks(df_campaign_desc.index)\n",
    "plt.ylabel('Amount of coupons')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the difference between the amount of coupon distributed and redeemed differs a lot from one campaign to another. It goes from cases where it is nearly null (such as campaign 1) to extreme cases where no coupons were redeemed (such as in campaigns 6, 15 and 24). To understand what happened here, we will need to inspect more precisely each campaign and join our results with data about the products and the transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marital_dict = {\"A\": \"Married\", \"B\": \"Single\", \"U\": \"Unknown\"}\n",
    "household_size_dict = {\"1\": 1, \"2\": 2, \"3\": 3, \"4\": 4, \"5+\": 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo = pd.read_csv(\"dunnhumby/hh_demographic.csv\")\n",
    "df_demo.columns = map(str.lower, df_demo.columns)\n",
    "\n",
    "# Replace cryptic character with actual label\n",
    "df_demo[\"married\"] = df_demo[\"marital_status_code\"].apply(\n",
    "    lambda code: marital_dict[code]\n",
    ")\n",
    "\n",
    "# Create new column with numerical household size\n",
    "for hh_str, hh_int in household_size_dict.items():\n",
    "    df_demo[\"household_size_desc_numeric\"] = df_demo[\"household_size_desc\"].replace(\n",
    "        hh_str, hh_int\n",
    "    )\n",
    "df_demo[\"household_size_desc_numeric\"] = df_demo[\"household_size_desc_numeric\"].astype(int)\n",
    "    \n",
    "df_demo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see from which age groups we have the most people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo[\"age_desc\"].value_counts().sort_index().plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products = pd.read_csv('dunnhumby/product.csv')\n",
    "df_products.columns = map(str.lower, df_products.columns)\n",
    "df_products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the product data frame and filter for anything food related. The columns *department*, *commodity_desc* and *sub_commodity_desc* desccribe the product category. We do the whole process manually. We create the most common food categories like meat, seafood, fruits, etc. We fill this categories with words and filter the product dataframe. Food item that we find in a rest dataframe (contains items which weren't assigned to any category yet), we add to the category lists. We do this step iteratively until no food items are left in the rest dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataframe(df, word_list):\n",
    "    filtered_df = df.copy()\n",
    "    for word in word_list:\n",
    "        filtered_df = filtered_df[~(filtered_df[\"department\"].str.contains(word) | filtered_df[\"commodity_desc\"].str.contains(word) | filtered_df[\"sub_commodity_desc\"].str.contains(word))]\n",
    "    return df[~df.index.isin(filtered_df.index)], df[df.index.isin(filtered_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meat_list = [\"MEAT\",\"PORK\", \"BEEF\", \"DUCK\", \"CHICKEN\", \"POULTRY\", \"LAMB\", \"VEAL\",\n",
    "             \"MUTTON\", \"TURKEY\", \"VENISON\", \"WILD BOAR\", \"BISON\", \"GOOSE\", \"RABBIT\", \"PHEASANT\"]\n",
    "seafood_list = [\"HERRING\", \"SEAFOOD\", \"SEAFD\",\"SUSHI\", \"FISH\",\"SHRIMP\",\"SALMON\",\"TUNA\",\n",
    "                \"TILAPIA\",\"ALASKA\",\"POLLOCK\",\"PANGASIUS\",\"BASA\",\"SWAI\",\"COD\",\"CATFISH\",\"CRAB\",\"CLAMS\"]\n",
    "sweets_snack_list = [\"ROLLS\", \"GUM\", \"PASTRY\", \"NUT\",\"CRACKERS\",\"DESSERT\",\"SNKS\",\"SNACK\",\"CHIP\",\n",
    "                     \"CANDY\", \"ICE\", \"SWEET\", \"CHOCOLATE\",\"POPCORN\", \"CAKE\", \"COOKIE\", \"PANCAKE\",\n",
    "                     \"BAKING\", \"BAKE\", \"PIE\"]\n",
    "fruits_list = [\"FRUIT\",\"APPLE\", \"ORANGE\", \"PEAR\", \"BANANA\", \"GRAPE\", \"BERR\", \"TOMATO\", \"LEMON\", \"MELON\", \"PEACH\", \"CHERR\", \"PINEAPPLE\", \"CITRUS\"]\n",
    "vegetable_list = [\"PUMPKIN\", \"COLESLAW\", \"SPINACH\", \"BEAN\",\"VEG\", \"POTATO\", \"CARROT\",\"CORN\",\"PEPPER\", \"SQUASH\", \"ONION\", \"MUSHROOM\", \"CUCUMBER\", \"CAULIFLOWER\", \"BROCCOLI\", \"OLIVE\" ]\n",
    "veg_animal_list = [\"DAIRY\",\"MILK\",\"CHEESE\", \"YOGURT\", \"BUTTER\", \"MARGARINE\", \"EGG\", \"HONEY\"]\n",
    "beverage_list = [\"CIDER\", \"BEVERAGE\", \"WATER\", \"COKE\", \"FANTA\", \"SPRITE\",\"LIQUOR\", \"LEMONADE\", \"COCOA\", \"VODKA\", \"BEER\", \"WINE\", \"COFFEE\", \"DRINK\", \"TEA\", \"JUICE\", \"DRNKS\", \"JCE\"]\n",
    "condiment_list = [\"GARLIC\",\"SALSA\",\"FLOUR\", \"DIP\",\"OIL\",\"SEASONING\",\"JELLY\", \"JAM\",\"SAUCE\", \"HERBS\", \"CONDIMENT\", \"TOPPING\", \"SYRUP\", \"DRESSING\", \"KETCHUP\", \"MAYO\", \"DRSNG\"]\n",
    "carbs_list = [\"NOODLES\", \"PASTA\", \"CROUTON\",\"RICE\", \"BREAD\", \"TOAST\", \"CEREAL\", \"OATMEAL\", \"DOUGH\", \"POTATO\"]\n",
    "meal_list = [\"PIZZA\", \"RAMEN\", \"SANDWICH\", \"SALAD\",\"SOUP\",\"ENTREE\", \"DINNER\", \"BREAKFAST\", \"THAI\", \"ASIAN\", \"ITALIAN\", \"MEXICAN\", \"GERMAN\", \"BURRITO\", \"FOOD\", \"ORIENTAL\", \"DISH\", \"KOSHER\"]\n",
    "\n",
    "df_meat, df_rest = filter_dataframe(df_products, meat_list)\n",
    "df_seafood, df_rest = filter_dataframe(df_rest, seafood_list)\n",
    "df_sweets_snack, df_rest = filter_dataframe(df_rest, sweets_snack_list)\n",
    "df_fruits, df_rest = filter_dataframe(df_rest, fruits_list)\n",
    "df_vegetable, df_rest = filter_dataframe(df_rest, vegetable_list)\n",
    "df_veg_animal, df_rest = filter_dataframe(df_rest, veg_animal_list)\n",
    "df_beverage, df_rest = filter_dataframe(df_rest, beverage_list)\n",
    "df_condiments, df_rest = filter_dataframe(df_rest, condiment_list)\n",
    "df_carbs, df_rest = filter_dataframe(df_rest, carbs_list)\n",
    "df_meals, df_rest = filter_dataframe(df_rest, meal_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_rest[\"sub_commodity_desc\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food = pd.concat([df_meat, df_seafood, df_sweets_snack, df_fruits, df_vegetable, df_veg_animal, df_beverage, df_condiments, df_carbs, df_meals])\n",
    "df_food.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfoods_no_size = df_food[df_food[\"curr_size_of_product\"] == \" \"].count()[\"product_id\"]\n",
    "nfoods = df_food.count()[\"product_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We have size info for {:.2f}% of food products\".format(100 * (1 - nfoods_no_size / nfoods)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transaction data and price analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transaction = pd.read_csv('dunnhumby/transaction_data.csv')\n",
    "df_transaction.columns = map(str.lower, df_transaction.columns)\n",
    "df_transaction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us join the food and transaction data for more insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_trans = pd.merge(df_food, df_transaction, on='product_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_households = len(df_food_trans[\"household_key\"].unique())\n",
    "print('The dataset contains {} individual households.'.format(number_households))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check what percentile of the households did not buy meat and seafood products at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meat_seafood = df_meat.append(df_seafood).drop_duplicates()\n",
    "df_meat_seafood.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meat_seafood_trans = pd.merge(df_meat_seafood, df_transaction, on='product_id', how='left')\n",
    "number_household_meat_seafood = len(df_meat_seafood_trans[\"household_key\"].unique())\n",
    "print(\"Number of households who did not purchased any meat or seafood: % d\" %(number_households-number_household_meat_seafood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_meat_sea = df_meat_seafood_trans.groupby(\"week_no\").count()[\"product_id\"]\n",
    "weekly_trans = df_food_trans.groupby(\"week_no\").count()[\"product_id\"]\n",
    "plt.plot(weekly_meat_sea)\n",
    "plt.xlabel(\"Week\")\n",
    "plt.ylabel(\"Number of Meat and Seafood Transactions\")\n",
    "plt.title(\"Meat and Seafood Transactions [Weekly]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall there is no upwards or downwards trend of meat and seafood transactions. But it is weird that the meat and seafood transactions rose rapidly in the first few weeks. It is likely that in the beginning not all transactions were caught. We take a look at the relation between the number of transactions and the number of meat and seafood transactions. If the rise in the beginning is only due to the fact that not all transactions were recorded, then the relation should be linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(weekly_trans, weekly_meat_sea)\n",
    "plt.xlabel(\"Number of Transactions\")\n",
    "plt.ylabel(\"Number of Meat and Seafood Transactions\")\n",
    "plt.title(\"Meat and Seafood Transaction in Relation to overall Number of Transactions [Weekly]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relation is indeed linear.\n",
    "\n",
    "Next we take a look at the number of households which weekly buy meat or seafood products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_meat_seafood_trans.groupby(\"week_no\")[\"household_key\"].nunique())\n",
    "plt.xlabel(\"Week\")\n",
    "plt.ylabel(\"Number of Households that purchased Meat or Seafood\")\n",
    "plt.title(\"Households that purchased Meat and Seafood Transactions [Weekly]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number again stays relatively stable at around 800-900. That is surprising, because the number of households which did purchase a meat product in the two years is 2475.\n",
    "\n",
    "Let's check the number of households, which go vegetarian in a week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_vege = df_food_trans.groupby(\"week_no\")[\"household_key\"].nunique()-df_meat_seafood_trans.groupby(\"week_no\")[\"household_key\"].nunique()\n",
    "plt.plot(weekly_vege)\n",
    "plt.xlabel(\"Week\")\n",
    "plt.ylabel(\"Number of Households that purchased Meat or Seafood\")\n",
    "plt.title(\"Relation of overall households and households that bought meat or seafood [Weekly]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly the number is super high considering that almost all households do not live completely vegetarian. Lets check the frequency of the meat and seafood purchases of all households."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_purchase = df_meat_seafood_trans.groupby(\"household_key\").count()[\"product_id\"]\n",
    "print(house_purchase.sort_values(ascending=False).head(10))\n",
    "plt.hist(house_purchase, bins=50)\n",
    "plt.xlabel(\"Number of meat and seafood transactions\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histrogram for Meat and SEAFOOD transaction in a household\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categories of coupons per campaign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do some further analysis, we will create a function *products_categories()* taking the number of a campaign and plotting the repartition of products for which coupons were offered and were redeemed based on the categories previously defined. It will also return these 2 repartitions as dictionaries with the proportion of each category as values and the categories as keys. A parameter *show_plot* will enable to show or not the plot (if only the proportions are needed). Note that the proportions for the coupons redeemed are computed as the proportion out of the total number of coupons distributed (i.e. 20% coupons redeemed in 'meat' means that 20% of the coupons distributed were redeemed for 'meat'). This is not the same as saying that 20% of the coupons redeemed were for 'meat'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df with all remaining products (even non-food products)\n",
    "df_left_all = df_products[\n",
    "    ~df_products.index.isin(\n",
    "        np.concatenate(\n",
    "            (\n",
    "                df_meat.index,\n",
    "                df_seafood.index,\n",
    "                df_sweets_snack.index,\n",
    "                df_fruits.index,\n",
    "                df_vegetable.index,\n",
    "                df_beverage.index,\n",
    "                df_veg_animal.index,\n",
    "                df_condiments.index,\n",
    "                df_carbs.index,\n",
    "                df_meals.index,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categories of food (previously defined)\n",
    "categories = ['Meat', 'Seafood', 'Sweet snacks', 'Fruits', 'Vegetables', 'Veg animal', 'Beverage', 'Condiments', 'Carbs', 'Meals', 'Other']\n",
    "df_list = (df_meat, df_seafood, df_sweets_snack, df_fruits, df_vegetable, \n",
    "           df_veg_animal, df_beverage, df_condiments, df_carbs, df_meals, df_left_all)\n",
    "\n",
    "def products_categories(num_camp, show_plot = False):\n",
    "    proportions_dist = dict.fromkeys(categories)\n",
    "    proportions_red = dict.fromkeys(categories)\n",
    "    \n",
    "    #Compute the number of coupons in each category\n",
    "    for categ,df in enumerate(df_list):\n",
    "        #Check if coupon of a category are given for a specific campaign, otherwise simply puts 0 coupons (for coupons distributed)\n",
    "        if num_camp in df.merge(df_coupon, on = 'product_id').groupby(by = 'campaign').count().index:\n",
    "            proportions_dist[categories[categ]] = df.merge(df_coupon, on = 'product_id').groupby(by = 'campaign').count().loc[num_camp][1] \n",
    "        else:\n",
    "            proportions_dist[categories[categ]] = 0\n",
    "        #Check if coupon of a category are given for a specific campaign, otherwise simply puts 0 coupons (for coupons redeemed)    \n",
    "        if num_camp in df.merge(df_coupon[df_coupon.redeemed], on = 'product_id').groupby(by = 'campaign').count().index:  \n",
    "            proportions_red[categories[categ]] = df.merge(df_coupon[df_coupon.redeemed],\n",
    "                                                          on = 'product_id').groupby(by = 'campaign').count().loc[num_camp][1] \n",
    "        else:\n",
    "            proportions_red[categories[categ]] = 0\n",
    "    \n",
    "    #Compute the proportion as percentage\n",
    "        #Compute the total number of coupons distributed\n",
    "    total = 0\n",
    "    for i in proportions_dist.values(): \n",
    "           total += i \n",
    "    if total != 0:\n",
    "        #Compute proportion of coupons distributed per category\n",
    "        for key in proportions_dist.keys():\n",
    "            proportions_dist[key] = 100*proportions_dist[key]/total\n",
    "        #Compute proportion of coupons redeemed per category (proportion of the total number of coupons distributed)\n",
    "            proportions_red[key] = 100*proportions_red[key]/total\n",
    "    \n",
    "    #Plot the repartitions of products for which coupons were offered\n",
    "    if show_plot:   \n",
    "        # set width of bar\n",
    "        barWidth = 0.4\n",
    " \n",
    "        # Set position of bar on X axis\n",
    "        r = np.arange(len(proportions_dist))\n",
    "        r1 = [x - barWidth/2 for x in r]\n",
    "        r2 = [x + barWidth/2 for x in r]\n",
    " \n",
    "        # Make the plot\n",
    "        plt.bar(r1, list(proportions_dist.values()), width=barWidth, edgecolor='white', label='Distributed coupons')\n",
    "        plt.bar(r2, list(proportions_red.values()), width=barWidth, edgecolor='white', label='Redeemed coupons')\n",
    "        plt.xticks(range(len(proportions_dist)), list(proportions_dist.keys()))\n",
    "        plt.title('Proportions of coupons per category during campaign ' + str(num_camp))\n",
    "        plt.xlabel('Categories')\n",
    "        plt.ylabel('Proportion of coupons [%]')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    return (proportions_dist, proportions_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the coupons distributed are spread over the different categories for campaign 4 for instance (a campaign mainly about sweet snacks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(prop_dist, prop_red) = products_categories(4, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now take a more overall view, across all campaign. We will compute the proportions of coupons distributed in each category for all campaigns and plot the results in a stacked bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportions_dist_overall = pd.DataFrame(columns = categories)\n",
    "for i in range(30):\n",
    "    proportions_dist_overall = proportions_dist_overall.append(products_categories(i+1)[0], ignore_index = True)\n",
    "proportions_dist_overall.set_index(df_campaign_desc.index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportions_dist_overall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportions_dist_overall.plot.bar(stacked = True)\n",
    "plt.title('Proportions of coupon distributed per category for each campaign')\n",
    "plt.xticks(rotation = 'horizontal')\n",
    "plt.ylabel('Proportions of coupon [%]')\n",
    "plt.legend(loc = 5, bbox_to_anchor = (1.13,0.77))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same for the proportions of coupons redeemed per category for each campaign. Note that in this case the total will not add to 100% as not all coupons are redeemed during a campaign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportions_red_overall = pd.DataFrame(columns = categories)\n",
    "for i in range(30):\n",
    "    proportions_red_overall = proportions_red_overall.append(products_categories(i+1)[1], ignore_index = True)\n",
    "proportions_red_overall.set_index(df_campaign_desc.index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportions_red_overall.plot.bar(stacked = True)\n",
    "plt.title('Proportions of coupon redeemed per category for each campaign')\n",
    "plt.xticks(rotation = 'horizontal')\n",
    "plt.ylabel('Proportions of coupon [%]')\n",
    "plt.legend(loc = 5, bbox_to_anchor = (1.13,0.77))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vegetarian vs non-vegetarian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see, it is still quite hard to understand what is happening. We will thus group products in fewer categories: vegetarian, non-vegetarian, unknown and other. The 'unknown' category comprises all categories were the exact list of ingredients would be needed to know if it is vegetarian or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportions_dist_final = pd.DataFrame()\n",
    "proportions_dist_final['Vegetarian'] = proportions_dist_overall['Fruits'] + proportions_dist_overall['Vegetables'] + proportions_dist_overall['Veg animal'] + proportions_dist_overall['Carbs']\n",
    "proportions_dist_final['Non-vegetarian'] = proportions_dist_overall['Meat'] + proportions_dist_overall['Seafood']\n",
    "proportions_dist_final['Unknown'] = proportions_dist_overall['Sweet snacks'] + proportions_dist_overall['Beverage'] + proportions_dist_overall['Condiments'] + proportions_dist_overall['Meals']\n",
    "proportions_dist_final['Other'] = proportions_dist_overall['Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportions_dist_final.plot.bar(stacked = True, color = ['green', 'red', 'blue', 'grey'])\n",
    "plt.title('Proportions of coupon distributed per category for each campaign')\n",
    "plt.xticks(rotation = 'horizontal')\n",
    "plt.ylabel('Proportions of coupon [%]')\n",
    "plt.legend(loc = 5, bbox_to_anchor = (1.14,0.77))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportions_red_final = pd.DataFrame()\n",
    "proportions_red_final['Vegetarian'] = proportions_red_overall['Fruits'] + proportions_red_overall['Vegetables'] + proportions_red_overall['Veg animal'] + proportions_red_overall['Carbs']\n",
    "proportions_red_final['Non-vegetarian'] = proportions_red_overall['Meat'] + proportions_red_overall['Seafood']\n",
    "proportions_red_final['Unknown'] = proportions_red_overall['Sweet snacks'] + proportions_red_overall['Beverage'] + proportions_red_overall['Condiments'] + proportions_red_overall['Meals']\n",
    "proportions_red_final['Other'] = proportions_red_overall['Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportions_red_final.plot.bar(stacked = True, color = ['green', 'red', 'blue', 'grey'])\n",
    "plt.title('Proportions of coupon redeemed per category for each campaign')\n",
    "plt.xticks(rotation = 'horizontal')\n",
    "plt.ylabel('Proportions of coupon [%]')\n",
    "plt.legend(loc = 5, bbox_to_anchor = (1.14,0.77))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a more overall view at the vegetarian vs non-vegetarian proportions of coupons distributed and redeemed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2)\n",
    "\n",
    "axes[0].boxplot((proportions_dist_final['Vegetarian'],proportions_dist_final['Non-vegetarian']), \n",
    "                labels = ('Vegetarian', 'Non-vegetarian'),\n",
    "                notch = True, bootstrap = 1000, #Add CI for median, computed through bootstrap with n = 1000\n",
    "                widths = 0.6,\n",
    "                showmeans = True) #Add arithmetic means as green triangle\n",
    "axes[0].set_title('Coupons distributed')\n",
    "axes[1].boxplot((proportions_red_final['Vegetarian'],proportions_red_final['Non-vegetarian']), \n",
    "                labels = ('Vegetarian', 'Non-vegetarian'),\n",
    "                notch = True, bootstrap = 1000, #Add CI for median, computed through bootstrap with n = 1000\n",
    "                widths = 0.6,\n",
    "                showmeans = True) #Add arithmetic means as green triangle\n",
    "axes[1].set_title('Coupons redeemed')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlabel('Category')\n",
    "    ax.set_ylabel('Proportion of coupons')\n",
    "\n",
    "fig.suptitle('Vegetarian vs non-vegetarian proportions of coupons (overall view)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advertisement analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_causal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by changing the 'display' and 'mailer' values to make them more explicit. We will define two dict and then use the map() method for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_dict = {'0':'Not on Display', '1':'Store Front', '2':'Store Rear', '3':'Front End Cap',\n",
    "                '4':'Mid-Aisle End Cap', '5':'Read End Cap', '6':'Side-Aisle End Cap', '7':'In-Aisle' ,\n",
    "                '9':'Secondary Location Display' ,'A':'In-Shelf' }\n",
    "mailer_dict = {'0':'Not on ad', 'A':'Interior page feature', 'C':'Interior page line item', \n",
    "              'D':'Front page feature', 'F':'Back page feature', 'H':'Wrap front feature',\n",
    "              'J':'Wrap interior coupon', 'L':'Wrap back feature', 'P':'Interior page coupon',\n",
    "              'X':'Free on interior page', 'Z':'Free on front page, back page or wrap'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_causal.display = df_causal.display.apply(lambda x: str(x))\n",
    "df_causal.display = df_causal.display.map(display_dict, na_action = 'ignore')\n",
    "df_causal.mailer = df_causal.mailer.map(mailer_dict, na_action = 'ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's observe how many products we have in each category, both for display and mailer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_causal.groupby(by = 'display').count().mailer.plot(kind = 'barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, many products are simply not in display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_causal.groupby(by = 'mailer').count().display.plot(kind = 'barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the largest numbers of ads are in the interior or front pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now analyse the ads distribution for each category of food previously defined. To do this, we will define a function ads_categories() that will take a dataframe (one of the 11 dataframes of the categories of food) and return the distribution of ads (as percentages). A show_plot parameter will decide if we want to directly plot the distribution in a bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ads_categories(df, categ = '', show_plot = False):\n",
    "    count = df.merge(df_causal, on = 'product_id').groupby(by = 'mailer').display.count()\n",
    "    proportions = count.map(lambda x: 100*x/count.sum())\n",
    "    \n",
    "    if show_plot:\n",
    "        proportions.plot.bar()\n",
    "        plt.title('Proportion of mailer ads for %s' %categ)\n",
    "        plt.xlabel('Type of ads')\n",
    "        plt.xticks(rotation = 30)\n",
    "        plt.ylabel('Proportion of ads [%]')\n",
    "        plt.show()\n",
    "    \n",
    "    return (proportions,count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give an example for meat for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(prop_meat,count_meat) = ads_categories(df_meat, 'meat', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a dataframe to store the ads proportions for each category of food."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ads_prop = pd.DataFrame(index = mailer_dict.values(), columns = categories)\n",
    "df_ads_prop.sort_index(inplace = True)\n",
    "df_ads_prop.index.name = 'Type of ads'\n",
    "\n",
    "df_ads_count = pd.DataFrame(index = mailer_dict.values(), columns = categories)\n",
    "df_ads_count.sort_index(inplace = True)\n",
    "df_ads_count.index.name = 'Type of ads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,df in enumerate(df_list):\n",
    "    df_ads_prop[categories[i]] = ads_categories(df)[0]\n",
    "    df_ads_count[categories[i]] = ads_categories(df)[1]\n",
    "df_ads_prop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice some values are set to NaN. This happens because, if there are no ads of the specific type of mailer, it is simply missing from the series. We can therefore simply fill all NaN values with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ads_prop.fillna(0, inplace = True)\n",
    "df_ads_count.fillna(0, inplace = True)\n",
    "df_ads_prop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ads_prop.transpose().plot.bar(stacked = True) #The transpose() is needed to get the right kind of stacked barplot\n",
    "plt.title('Proportions of types of ads per category of food')\n",
    "plt.xticks(rotation = 'horizontal')\n",
    "plt.ylabel('Proportions of types of ads [%]')\n",
    "plt.legend(loc = 5, bbox_to_anchor = (1.28,0.77))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look more precisely at Not on ad, Front page feature, Interior page feature and Back page feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = range(len(categories)), y = df_ads_prop.transpose()['Not on ad'], \n",
    "            label = 'Not on ad', marker = 'x', s = 200)\n",
    "plt.scatter(x = range(len(categories)), y = df_ads_prop.transpose()['Front page feature'], \n",
    "            label = 'Front page feature', marker = '+', s = 200)\n",
    "plt.scatter(x = range(len(categories)), y = df_ads_prop.transpose()['Interior page feature'], \n",
    "            label = 'Interior page feature', marker = 'd', s = 200)\n",
    "plt.scatter(x = range(len(categories)), y = df_ads_prop.transpose()['Back page feature'], \n",
    "            label = 'Back page feature', marker = '^', s = 200)\n",
    "plt.xticks(range(len(categories)), list(categories))\n",
    "plt.title('Proportions of main types of ads per category of food')\n",
    "plt.xlabel('Category of food')\n",
    "plt.ylabel('Percentage of ads [%]')\n",
    "plt.legend(loc = 5, bbox_to_anchor = (1.2,0.77))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that meat ads are mainly situated in the interior pages with very few in the back pages. On the contrary, fruits have much more ads in the back pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will focus ourselfs on the prices of the products. We will start by some basic statistical analysis and then group products in the previously defined categories and try to extract some meaningful conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clarify what the less obvious columns represent. The SALES_VALUE is the amount of dollar received by the retailer for a particular sale. The RETAIL_DISC is a discount applied due to retailer's loyalty card program. The COUPON_DISC is a discount applied due to manufacturer coupon and COUPON_MATCH_DISC a discount applied due to retailer's match of manufacturer coupon. Finally, the TRANS_TIME correspond to the time of the day the purchase was made (ranging from 0 to 2359, i.e. from 0:00 to 23:59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We have %d transactions in our dataset.' %len(df_transaction))\n",
    "print('We have %d transactions in our dataset with QUANTITY = 0.' %len(df_transaction[df_transaction.quantity == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by discarding all transcations for which the quantity is null (as no item has actually been sold in these cases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transaction = df_transaction[df_transaction.quantity > 0]\n",
    "print('We have %d transactions left in our dataset.' %len(df_transaction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the actual product prices (with or without loyalty card). To do so, we use the following formulas (as explained in the user guide):\n",
    "- Loyalty card price = (sales_value – (retail_disc + coupon_match_disc))/quantity\n",
    "- Non-loyalty card price = (sales_value – coupon_match_disc)/quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transaction['loyalty_card_price'] = (df_transaction['sales_value'] - (df_transaction['retail_disc'] + df_transaction['coupon_match_disc']))/df_transaction['quantity']\n",
    "df_transaction['no_loyalty_card_price'] = (df_transaction['sales_value'] - df_transaction['coupon_match_disc'])/df_transaction['quantity']\n",
    "df_transaction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.describe(df_transaction['sales_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('50% of the transations are below ' + str(df_transaction['sales_value'].median()) + '$.')\n",
    "print('80% of the transations are below ' + str(df_transaction['sales_value'].quantile(0.8)) + '$.')\n",
    "print('There are %d transactions with sales value 0.' %len(df_transaction[df_transaction['sales_value'] == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual price (with and without loyalty card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.describe(df_transaction['loyalty_card_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('50% of the prices (with loyalty card) are below ' + str(df_transaction['loyalty_card_price'].median()) + '$.')\n",
    "print('80% of the prices (with loyalty card) are below ' + str(df_transaction['loyalty_card_price'].quantile(0.8)) + '$.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.describe(df_transaction['no_loyalty_card_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('50% of the prices (without loyalty card) are below ' + str(df_transaction['no_loyalty_card_price'].median()) + '$.')\n",
    "print('80% of the prices (without loyalty card) are below ' + str(df_transaction['no_loyalty_card_price'].quantile(0.8)) + '$.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discounts (retailer and coupons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.describe(df_transaction['retail_disc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.describe(df_transaction['coupon_disc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.describe(df_transaction['coupon_match_disc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transaction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The TRANS_TIME ranges between %d and %d.' %(df_transaction['trans_time'].min(), df_transaction['trans_time'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demographics and Food"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we see if there are different buying habits for older/younger peopl? Let's start by combining our demographic data with the transactions. Then we'll annotate all transactions, if they're meat or other food."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transaction_per_household = df_transaction.merge(df_demo, on=\"household_key\")\n",
    "\n",
    "df_transaction_per_household[\"category\"] = \"unknown\"\n",
    "\n",
    "# First, let's mark everything that is food\n",
    "df_transaction_per_household.loc[\n",
    "    df_transaction_per_household[\"product_id\"].isin(df_food[\"product_id\"]), \"category\"\n",
    "] = \"other-food\"\n",
    "\n",
    "# Then we overwrite all entries that are actually meat\n",
    "df_transaction_per_household.loc[\n",
    "    df_transaction_per_household[\"product_id\"].isin(df_meat[\"product_id\"]), \"category\"\n",
    "] = \"meat\"\n",
    "\n",
    "df_transaction_per_household"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create a temporary dataframe to compute a meat ratio for each for each household. We do this by grouping by the households and then doing the calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = (\n",
    "    df_transaction_per_household.groupby(\"household_key\")[\"category\"]\n",
    "    .value_counts()\n",
    "    .to_frame()\n",
    "    .unstack()\n",
    ")\n",
    "\n",
    "# Drop the multi-columns, so we can\n",
    "# use simple indexing for ratio_meat\n",
    "aa.columns = aa.columns.droplevel()\n",
    "\n",
    "aa[\"ratio_meat\"] = aa[\"meat\"] / (aa[\"meat\"] + aa[\"other-food\"])\n",
    "\n",
    "# Get household_key as a column\n",
    "aa = aa.reset_index()\n",
    "\n",
    "aa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we combine our data to receive a new dataframe that enriches our existing demographic dataframe with a \"meat ratio\". This ratio tells us, how much of the bought food is considered meat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine our newly computed ratio_meat and the old household data\n",
    "df_demo_w_meat = df_demo.merge(aa[[\"household_key\", \"ratio_meat\"]], on=\"household_key\")\n",
    "\n",
    "# Normalize our ratio_meat by the size of the households\n",
    "df_demo_w_meat[\"ratio_meat\"] /= df_demo_w_meat[\"household_size_desc_numeric\"]\n",
    "\n",
    "df_demo_w_meat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to get a sense of the data, we'll plot it. Grouped by three different attributes: marital status, age and income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_index = [\n",
    "    \"Under 15K\",\n",
    "    \"15-24K\",\n",
    "    \"25-34K\",\n",
    "    \"35-49K\",\n",
    "    \"50-74K\",\n",
    "    \"75-99K\",\n",
    "    \"100-124K\",\n",
    "    \"125-149K\",\n",
    "    \"150-174K\",\n",
    "    \"175-199K\",\n",
    "    \"200-249K\",\n",
    "    \"250K+\",\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3)\n",
    "interesting_groups = [\"age_desc\", \"married\", \"income_desc\"]\n",
    "\n",
    "for i, group_name in enumerate(interesting_groups):\n",
    "    data = df_demo_w_meat.groupby(group_name).ratio_meat.mean()\n",
    "\n",
    "    means = []\n",
    "    for _ in range(500):\n",
    "        bs_resample_per_group = df_demo_w_meat.groupby(group_name).apply(\n",
    "            lambda x: x.sample(frac=1.0, replace=True)\n",
    "        )\n",
    "\n",
    "        bs_mean = bs_resample_per_group.ratio_meat.groupby(group_name).mean()\n",
    "\n",
    "        means.append(bs_mean)\n",
    "    means = pd.DataFrame(means)\n",
    "\n",
    "    qupper = means.quantile(0.975)\n",
    "    qlower = means.quantile(0.025)\n",
    "\n",
    "    if group_name == \"income_desc\":\n",
    "        data = data.reindex(salary_index)\n",
    "\n",
    "    data.plot(kind=\"bar\", ax=axes[i], yerr=[data - qlower, qupper - data], capsize=10)\n",
    "\n",
    "    axes[i].set_ylabel(\"Percentage of meat of overall shoppings\")\n",
    "\n",
    "fig.suptitle(\"Percentages of meat purchases (95% CI)\")\n",
    "fig.set_figheight(22)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see two interesting things:\n",
    "\n",
    "- Married people seem to buy less food (might be that they buy fewer, but larger packs)\n",
    "- As the income rises, the amount of meat bought decreases. It then sharply increases for incomes of over 250k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's coming next\n",
    "\n",
    "* *Campaign and coupons analysis:* continue our analysis on how retailers promote different categories of food and how people respond to it. In practice, this means for instance combining what has already been done with the transactions to find out how much people save money thanks to these campaigns and if it differs from one category of food to another.\n",
    "\n",
    "* *Household behaviour:* continue our analysis on the demographics in order to find different behaviour (due to income or type of family) towards meat consumption and vegetarianism in general.\n",
    "\n",
    "* *Advertisement analysis:* continue analysis (look at both distribution of ads within one category of food and across all categories, which ones get more ads in the best displays) and combine results with campaign and coupons analysis.\n",
    "\n",
    "Ultimately, our goal would be to combine more and more our results in order to get a precise understanding of both retailers and consumers towards meat consumption and vegetarianism in general."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada] *",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
