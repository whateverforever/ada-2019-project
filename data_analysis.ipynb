{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (16, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of the data structure: \n",
    "Our main dataset [Dunnhumby - The complete journey](https://www.dunnhumby.com/careers/engineering/sourcefiles) comprises 8 csv files with the following tabular structure and content.\n",
    "\n",
    "#### Campaign Desc\n",
    "Description | Campaign ID | Start and End Day\n",
    "--- | --- | ---\n",
    "{TypeA, TypeB, TypeC} | int | int (probably day count from study)\n",
    "\n",
    "#### Campaign Table\n",
    "Description | Campaign ID | Household key\n",
    "--- | --- | ---\n",
    "{TypeA, TypeB, TypeC} | int | int\n",
    "\n",
    "#### Casual Data\n",
    "Product ID | Store ID | Week | Display location | Mailer location\n",
    "--- | --- | --- | --- | --- \n",
    "int | int | int | int | String\n",
    " | | | Advertisement in in-store display? | Featured as ad in weekly mailer\n",
    " \n",
    "#### Coupon Redemption\n",
    "Household ID | Day | Coupon ID | Campaign ID \n",
    "--- | --- | --- | --- \n",
    "int | int | int | int \n",
    "\n",
    "#### Coupon\n",
    "Coupon ID | Product ID | Campaign ID \n",
    "--- | --- | ---  \n",
    "int | int | int \n",
    "\n",
    "#### Demographic\n",
    "Age | Marital Status Code | Income | Homeowner | Household composition | Household size | Number of kids | Household Id\n",
    "--- | --- | --- | --- | --- | --- | --- | --- |\n",
    "(19-65+) | {A: Married, B: Single, U: Unknown} | | {Homeowner, Retired, etc.} | {Female/Male single, adults with/without kids, etc.} || (1-3+) |\n",
    "\n",
    "\n",
    "#### Products\n",
    "Product Id | Manufacturer Id | Departement  | Brand | Commodity description | Sub commodity description | Size\n",
    "--- | --- | --- | --- | --- | --- | --- \n",
    " | | {grocery, pastry, etc.} | {national/private} | | |\n",
    " \n",
    "### Transaction\n",
    "Household Id | Manufacturer Id | Week | Day | Time of Day | Product Id | Quantity | Sales value | Store Id | Retail discount | Coupon discount | Coupon match discount\n",
    "--- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | \n",
    " | | | | | | | What the shop actually gets | | | Loyalty program of retailer | Shop does not get price before discount | Shop does get price before discount\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading the data in pandas dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_causal = pd.read_csv('dunnhumby/causal_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_causal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define two dict for the code meaning of display and mailer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_dict = {0:'Not on Display', 1:'Store Front', 2:'Store Rear', 3:'Front End Cap',\n",
    "                4:'Mid-Aisle End Cap', 5:'Read End Cap' ,6:'Side-Aisle End Cap', 7:'In-Aisle' ,\n",
    "                9:'Secondary Location Display' ,'A':'In-Shelf' }\n",
    "mailer_dict = {0:'Not on ad', 'A':'Interior page feature', 'C':'Interior page line item', \n",
    "              'D':'Front page feature', 'F':'Back page feature', 'H':'Wrap front feature',\n",
    "              'J':'Wrap interior coupon', 'L':'Wrap back feature', 'P':'Interior page coupon',\n",
    "              'X':'Free on interior page', 'Z':'Free on front page, back page or wrap'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coupon redemption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coupon_redempt = pd.read_csv('dunnhumby/coupon_redempt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coupon_redempt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's study how many coupons were redeemed for each campaign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coupon_redempt.groupby(by = 'CAMPAIGN').count().plot.bar(y = 'COUPON_UPC', logy = True) \n",
    "plt.xlabel('Campaign')\n",
    "plt.ylabel('Number of coupons redeemed')\n",
    "plt.title('Number of coupons redeemded per campaign')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coupon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coupon = pd.read_csv('dunnhumby/coupon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coupon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's study how many coupons were distributed for each campaign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coupon.groupby(by = 'CAMPAIGN').count().plot.bar(y = 'COUPON_UPC', logy = True) \n",
    "plt.xlabel('Campaign')\n",
    "plt.ylabel('Number of coupons distributed')\n",
    "plt.title('Number of coupons distributed per campaign')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice there are definetely some campaigns with way more coupons than others. Is this related to the type of campaign?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a column stating if a coupon has been redeemed or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coupon['REDEEMED'] = df_coupon['COUPON_UPC'].isin(df_coupon_redempt['COUPON_UPC'])\n",
    "df_coupon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now observe the number of coupons that were not redeemed for each campaign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coupon[~df_coupon['REDEEMED']].groupby(by = 'CAMPAIGN').count().plot.bar(y = 'COUPON_UPC', logy = True) \n",
    "plt.xlabel('Campaign')\n",
    "plt.ylabel('Number of coupons not redeemed')\n",
    "plt.title('Number of coupons not redeemed per campaign')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo = pd.read_csv('dunnhumby/hh_demographic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_demo.head(20))\n",
    "df_demo[\"AGE_DESC\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products = pd.read_csv('dunnhumby/product.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the product data frame and filter out anything food related. We start by looking at the column *DEPARTMENT*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dep = np.sort(df_products[\"DEPARTMENT\"].unique())\n",
    "list_commodity = np.sort(df_products[\"COMMODITY_DESC\"].unique())\n",
    "list_sub = np.sort(df_products[\"SUB_COMMODITY_DESC\"].unique())\n",
    "\n",
    "frames = {}\n",
    "for l in list_dep:    \n",
    "    frames[l] = df_products[df_products[\"DEPARTMENT\"].apply(lambda x : x == l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_products.groupby(\"DEPARTMENT\").count()[\"PRODUCT_ID\"].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's observe the biggest categories and see whats in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames[\"GROCERY\"][\"COMMODITY_DESC\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the category **Grocery** is all over the place and contains basically anything what can be bought in a grocery store. The category is not really helpful and we have to check the sub categories.\n",
    "\n",
    "Lets check **Drug Gm** next and see, if there is anythin food-related in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames[\"DRUG GM\"][\"COMMODITY_DESC\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 'DIETARY AID PRODUCTS' (candy bar, novelty candy, candy bags-chocolate)\n",
    "* 'CANDY - PACKAGED'\n",
    "* 'CANDY - CHECKLANE'\n",
    "* 'INFANT FORMULA'\n",
    "* 'BABY FOODS' \n",
    "* 'DOMESTIC GOODS'\n",
    "* 'NATURAL HBC' (novelty candy)\n",
    "\n",
    "After looking at the commodities individually , these do have some food related stuff in them.\n",
    "\n",
    "In the end the following *DEPARTMENT* values are food related. There still some a lot of non food items. We have to filter them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dep_food = [\"GROCERY\", \"DRUG GM\", \"PRODUCE\", \"NUTRITION\", \"MEAT\",\"MEAT-PCKGD\",\"DELI\",\"PASTRY\", \"SEAFOOD-PCKGD\", \"SEAFOOD\", \n",
    "                 \"RESTAURANT\", \"MISC SALES TRAN\", \"SALAD BAR\", \"TRAVEL & LEISUR\", \"FROZEN GROCERY\", \"CHEF SHOPPE\", \"DAIRY DELI\", \n",
    "                 \"GM MERCH EXP\", \"DELI/SNACK BAR\", \"GRO BAKERY\", \"PORK\", \"MEAT-WHSE\"]\n",
    "non_food = [\"COSMETICS\", \"FLORAL\", \"CHARITABLE CONT\", \"MISC. TRANS.\", \"SPIRITS\", \"GARDEN CENTER\", \n",
    "            \"COUP/STR & MFG\", \"KIOSK-GAS\", \"RX\", \"CNTRL/STORE SUP\", \"POSTAL CENTER\", \"TOYS\", \n",
    "            \"VIDEO RENTAL\", \"PHOTO\", \"PROD-WHS SALES\", \"CHARITABLE CONT\", \"AUTOMOTIVE\", \"VIDEO\", \n",
    "            \"ELECT &PLUMBING\",\"HOUSEWARES\", \"PHARMACY SUPPLY\", \"HBC\", \" \"]\n",
    "print(list_dep_food)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_dep = df_products[df_products[\"DEPARTMENT\"].apply(lambda x : x in list_dep_food)]\n",
    "df_meat_dep = df_food_dep[df_food_dep[\"COMMODITY_DESC\"].str.contains(\"MEAT\")]\n",
    "df_fish_dep = df_food_dep[df_food_dep[\"COMMODITY_DESC\"].str.contains(\"FISH\")]\n",
    "np.sort(df_food_dep[\"COMMODITY_DESC\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_food_com = ['APPLES', 'BABY FOODS', 'BABYFOOD',\n",
    "       'BAG SNACKS', 'BAKED BREAD/BUNS/ROLLS',\n",
    "       'BAKED SWEET GOODS', 'BAKERY PARTY TRAYS', 'BAKING',\n",
    "       'BAKING MIXES', 'BAKING NEEDS',\n",
    "       'BEANS - CANNED GLASS & MW', 'BEEF', 'BEERS/ALES', 'BERRIES',\n",
    "       'BEVERAGE',\n",
    "       'BREAD', 'BREAKFAST SAUSAGE/SANDWICHES', 'BREAKFAST SWEETS',\n",
    "       'BROCCOLI/CAULIFLOWER', 'BULK FOODS', 'BUTTER',\n",
    "       'CAKES', 'CANDY - CHECKLANE',\n",
    "       'CANDY - PACKAGED', 'CANNED JUICES', 'CANNED MILK', 'CARROTS', 'CEREAL/BREAKFAST',\n",
    "         'CHEESE', 'CHEESES', 'CHICKEN',\n",
    "       'CHICKEN/POULTRY', 'CHIPS&SNACKS', 'CHRISTMAS  SEASONAL',\n",
    "        'CITRUS', 'COCOA MIXES', 'COFFEE', 'COFFEE SHOP', 'COFFEE SHOP SWEET GOODS&RETAIL',\n",
    "       'COLD CEREAL', 'CONDIMENTS', 'CONDIMENTS/SAUCES', 'CONVENIENT BRKFST/WHLSM SNACKS', 'COOKIES',\n",
    "       'COOKIES/CONES', 'CORN', 'CRACKERS/MISC BKD FD', 'DELI MEATS',\n",
    "       'DELI SPECIALTIES (RETAIL PK)', 'DELI SUPPLIES', 'DINNER MXS:DRY',\n",
    "       'DINNER SAUSAGE', 'DOMESTIC GOODS',\n",
    "       'DOMESTIC WINE', 'DRIED FRUIT', 'DRY BN/VEG/POTATO/RICE',\n",
    "       'DRY MIX DESSERTS', 'DRY NOODLES/PASTA', 'DRY SAUCES/GRAVY',\n",
    "       'DRY TEA/COFFEE/COCO MIX', 'EASTER', 'EGGS','EXOTIC GAME/FOWL',\n",
    "       'FALL AND WINTER SEASONAL',\n",
    "       'FITNESS&DIET', 'FLOUR & MEALS', 'FLUID MILK PRODUCTS', 'FROZEN',\n",
    "       'FROZEN - BOXED(GROCERY)', 'FROZEN BREAD/DOUGH', 'FROZEN CHICKEN',\n",
    "       'FROZEN MEAT', 'FROZEN PACKAGE MEAT', 'FROZEN PIE/DESSERTS',\n",
    "       'FROZEN PIZZA', 'FRUIT - SHELF STABLE', 'FRZN BREAKFAST FOODS',\n",
    "       'FRZN FRUITS', 'FRZN ICE', 'FRZN JCE CONC/DRNKS',\n",
    "       'FRZN MEAT/MEAT DINNERS', 'FRZN NOVELTIES/WTR ICE',\n",
    "       'FRZN POTATOES', 'FRZN SEAFOOD', 'FRZN VEGETABLE/VEG DSH', 'GRAPES',  'HEAT/SERVE', 'HERBS', 'HISPANIC',\n",
    "       'HOME FREEZING & CANNING SUPPLY','HOT CEREAL', 'HOT DOGS',\n",
    "        'ICE CREAM/MILK/SHERBTS',\n",
    "       'IMPORTED WINE',\n",
    "       'INFANT FORMULA',\n",
    "       'ISOTONIC DRINKS',  'JUICE' , 'LAMB',\n",
    "        'LIQUOR', 'LUNCHMEAT',\n",
    "        'MARGARINES', 'MEAT - MISC', 'MEAT - SHELF STABLE',\n",
    "       'MEAT SUPPLIES', 'MELONS', 'MILK BY-PRODUCTS', 'MISC WINE',\n",
    "       'MISC. DAIRY', 'MISCELLANEOUS', 'MISCELLANEOUS CROUTONS',\n",
    "       'MOLASSES/SYRUP/PANCAKE MIXS', 'MUSHROOMS', 'NATURAL HBC',\n",
    "       'NATURAL VITAMINS', 'NDAIRY/TEAS/JUICE/SOD', 'NEW AGE',\n",
    "        'NON-DAIRY BEVERAGES', 'NUTS',\n",
    "       'OLIVES', 'ONIONS',\n",
    "       'ORGANICS FRUIT & VEGETABLES', \n",
    "       'PACKAGED NATURAL SNACKS', \n",
    "       'PARTY TRAYS', 'PASTA SAUCE', 'PEARS', 'PEPPERS-ALL',\n",
    "       'PICKLE/RELISH/PKLD VEG', 'PIES', 'PKG.SEAFOOD MISC',\n",
    "        'PNT BTR/JELLY/JAMS', 'POPCORN', 'PORK',\n",
    "        'POTATOES',\n",
    "       'PREPARED FOOD',\n",
    "       'PREPARED/PKGD FOODS', 'PROCESSED', 'PROD SUPPLIES',\n",
    "       'PWDR/CRYSTL DRNK MX', 'QUICK SERVICE', 'REFRGRATD DOUGH PRODUCTS',\n",
    "       'REFRGRATD JUICES/DRNKS', 'REFRIGERATED', 'RESTRICTED DIET',\n",
    "       'RICE CAKES', 'ROLLS', 'RW FRESH PROCESSED MEAT', 'SALAD BAR',\n",
    "       'SALAD MIX', 'SALADS/DIPS', 'SALD DRSNG/SNDWCH SPRD', 'SANDWICHES',\n",
    "       'SEAFOOD - FROZEN', 'SEAFOOD - MISC', 'SEAFOOD - SHELF STABLE',\n",
    "       'SEAFOOD-FRESH', 'SEASONAL', 'SERVICE BEVERAGE',  'SHORTENING/OIL',\n",
    "        'SMOKED MEATS', \n",
    "       'SNACK NUTS', 'SNACKS', 'SNKS/CKYS/CRKR/CNDY', 'SOFT DRINKS', 'SOUP', 'SPICES & EXTRACTS',\n",
    "       'SPORTS MEMORABLILIA', 'SPRING/SUMMER SEASONAL', 'SQUASH',\n",
    "        'STONE FRUIT', 'SUGARS/SWEETNERS',\n",
    "        'SUSHI', 'SWEET GOODS & SNACKS', 'SYRUPS/TOPPINGS',\n",
    "       'TEAS', 'TOMATOES', \n",
    "       'TROPICAL FRUIT', 'TURKEY', 'UNKNOWN', \n",
    "       'VALUE ADDED FRUIT', 'VALUE ADDED VEGETABLES', 'VEAL',\n",
    "       'VEGETABLES - ALL OTHERS', 'VEGETABLES - SHELF STABLE',\n",
    "       'VEGETABLES SALAD', 'WAREHOUSE SNACKS', 'WATER',\n",
    "       'WATER - CARBONATED/FLVRD DRINK', 'YOGURT']\n",
    "print(list_food_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_com = df_food_dep[df_food_dep[\"COMMODITY_DESC\"].apply(lambda x : x in list_food_com)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the column *COMMODITY_DESC*, there are some categories, which are non ambigously only contain food items. But there are still categories like *BAKING NEEDS* which can contain non food items. We need to check their *SUB_COMMODITY_DESC* values for a description on the lowest level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_food_com_ambigious=['CHRISTMAS  SEASONAL', 'DOMESTIC GOODS','EASTER', 'FALL AND WINTER SEASONAL','HOME FREEZING & CANNING SUPPLY', 'NATURAL HBC', 'NATURAL VITAMINS','SEASONAL', 'SPORTS MEMORABLILIA', 'SPRING/SUMMER SEASONAL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BAKING MIXES, BAKING NEEDS contains seafood?!?\n",
    "\n",
    "Commodities to throw out (except):\n",
    "* NATURAL HBC – CANDY\n",
    "* NATURAL VITAMINS – PRETZELS\n",
    "* SEASONAL – PUMPKINS\n",
    "* SPORTS MEMORABLILIA – CANDY\n",
    "* 'SPRING/SUMMER SEASONAL' – CANDY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amb_com = df_food_com[df_food_com[\"COMMODITY_DESC\"].apply(lambda x : x in list_food_com_ambigious)]\n",
    "throw_out =['MISC', 'BAKING CUPS', 'CAKE DECORS - BIRTHDAY CANDLES', 'BANDANA/SCARVES', 'FLASHLIGHTS','AS SEEN ON TV', 'MISC BULK', 'MISC SALES TRANS','PEYTON/GM EXPENSE ITEMS', 'MICROWAVE'] \n",
    "\n",
    "for amb in list_food_com_ambigious:\n",
    "    for item in df_amb_com[df_amb_com[\"COMMODITY_DESC\"].apply(lambda x : x == amb)][\"SUB_COMMODITY_DESC\"].unique():\n",
    "        if not \"CANDY\" in item and not \"PUMPKINS\" in item and not \"PRETZELS\" in item:\n",
    "            throw_out.append(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final dataframe with only food."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food = df_food_com[df_food_com[\"SUB_COMMODITY_DESC\"].apply(lambda x : not x in throw_out)]\n",
    "\n",
    "df_food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataframe(df, word_list):\n",
    "    filtered_df = df.copy()\n",
    "    for word in word_list:\n",
    "        filtered_df = filtered_df[~(filtered_df[\"DEPARTMENT\"].str.contains(word) | filtered_df[\"COMMODITY_DESC\"].str.contains(word) | filtered_df[\"SUB_COMMODITY_DESC\"].str.contains(word))]\n",
    "    return df[~df.index.isin(filtered_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meat_list = [\"MEAT\",\"PORK\", \"BEEF\", \"DUCK\", \"CHICKEN\", \"POULTRY\", \"LAMB\", \"VEAL\", \"MUTTON\", \"TURKEY\", \"VENISON\", \"WILD BOAR\", \"BISON\", \"GOOSE\", \"RABBIT\", \"PHEASANT\"]\n",
    "seafood_list = [\"HERRING\", \"SEAFOOD\", \"SEAFD\",\"SUSHI\", \"FISH\",\"SHRIMP\",\"SALMON\",\"TUNA\",\"TILAPIA\",\"ALASKA\",\"POLLOCK\",\"PANGASIUS\",\"BASA\",\"SWAI\",\"COD\",\"CATFISH\",\"CRAB\",\"CLAMS\"]\n",
    "sweets_snack_list = [\"ROLLS\", \"PASTRY\", \"NUT\",\"CRACKERS\",\"DESSERT\",\"SNKS\",\"SNACK\",\"CHIP\", \"CANDY\", \"ICE\", \"SWEET\", \"CHOCOLATE\",\"POPCORN\", \"CAKE\", \"COOKIE\", \"PANCAKE\", \"BAKING\", \"BAKE\", \"PIE\"]\n",
    "fruits_list = [\"FRUIT\",\"APPLE\", \"ORANGE\", \"PEAR\", \"BANANA\", \"GRAPE\", \"BERR\", \"TOMATO\", \"LEMON\", \"MELON\", \"PEACH\", \"CHERR\", \"PINEAPPLE\", \"CITRUS\"]\n",
    "vegetable_list = [\"PUMPKIN\", \"COLESLAW\", \"SPINACH\", \"BEAN\",\"VEG\", \"POTATO\", \"CARROT\",\"CORN\",\"PEPPER\", \"SQUASH\", \"ONION\", \"MUSHROOM\", \"CUCUMBER\", \"CAULIFLOWER\", \"BROCCOLI\", \"OLIVE\" ]\n",
    "veg_animal_list = [\"DAIRY\",\"MILK\",\"CHEESE\", \"YOGURT\", \"BUTTER\", \"MARGARINE\", \"EGG\", \"HONEY\"]\n",
    "beverage_list = [\"CIDER\", \"BEVERAGE\", \"WATER\", \"COKE\", \"FANTA\", \"SPRITE\",\"LIQUOR\", \"LEMONADE\", \"COCOA\", \"BEER\", \"WINE\", \"COFFEE\", \"DRINK\", \"TEA\", \"JUICE\", \"DRNKS\", \"JCE\"]\n",
    "condiment_list = [\"SALSA\",\"FLOUR\", \"DIP\",\"OIL\",\"SEASONING\",\"JELLY\", \"JAM\",\"SAUCE\", \"HERBS\", \"CONDIMENT\", \"TOPPING\", \"SYRUP\", \"DRESSING\", \"KETCHUP\", \"MAYO\", \"DRSNG\"]\n",
    "carbs_list = [\"NOODLES\", \"PASTA\", \"CROUTON\",\"RICE\", \"BREAD\", \"TOAST\", \"CEREAL\", \"OATMEAL\", \"DOUGH\", \"POTATO\"]\n",
    "meal_list = [\"PIZZA\", \"RAMEN\", \"SANDWICH\", \"SALAD\",\"SOUP\",\"ENTREE\", \"DINNER\", \"BREAKFAST\", \"THAI\", \"ASIAN\", \"ITALIAN\", \"MEXICAN\", \"GERMAN\", \"BURRITO\", \"FOOD\", \"ORIENTAL\", \"DISH\"]\n",
    "df_meat = filter_dataframe(df_food, meat_list)\n",
    "df_seafood = filter_dataframe(df_food, seafood_list)\n",
    "df_sweets_snack = filter_dataframe(df_food, sweets_snack_list)\n",
    "df_fruits = filter_dataframe(df_food, fruits_list)\n",
    "df_vegetable = filter_dataframe(df_food, vegetable_list)\n",
    "df_veg_animal = filter_dataframe(df_food, veg_animal_list)\n",
    "df_beverage = filter_dataframe(df_food, beverage_list)\n",
    "df_condiments = filter_dataframe(df_food, condiment_list)\n",
    "df_carbs = filter_dataframe(df_food, carbs_list)\n",
    "df_meals = filter_dataframe(df_food, meal_list)\n",
    "df_left = df_food[~df_food.index.isin(np.concatenate((df_meat.index,df_seafood.index, df_sweets_snack.index, df_fruits.index, df_vegetable.index, df_beverage.index, df_veg_animal.index, df_condiments.index, df_carbs.index, df_meals.index)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left[\"SUB_COMMODITY_DESC\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transaction = pd.read_csv('dunnhumby/transaction_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transaction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's precise what does the less obvious column represent. The SALES_VALUE is the amount of dollar received by the retailer for a particular sale. The RETAIL_DISC is a discount applied due to retailer's loyalty card program. The COUPON_DISC is a discount applied due to manufacturer coupon and COUPON_MATCH_DISC a discount applied due to retailer's match of manufacturer coupon. Finally, the TRANS_TIME correspond to the time of the day the purchase was made (ranging from 0 to 2359, i.e. from 0:00 to 23:59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The TRANS_TIME ranges between %d and %d.' %(df_transaction['TRANS_TIME'].min(), df_transaction['TRANS_TIME'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the actual product prices (with or without loyalty card). To do so, we use the following formulas (as explained in the user guide):  \n",
    "    - Loyalty card price = (sales_value – (retail_disc + coupon_match_disc))/quantity  \n",
    "    - Non-loyalty card price = (sales_value – (coupon_match_disc))/quantity \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transaction['LOYALTY_CARD_PRICE'] = (df_transaction['SALES_VALUE'] - (df_transaction['RETAIL_DISC'] + df_transaction['COUPON_MATCH_DISC']))/df_transaction['QUANTITY']\n",
    "df_transaction['NO_LOYALTY_CARD_PRICE'] = (df_transaction['SALES_VALUE'] - df_transaction['COUPON_MATCH_DISC'])/df_transaction['QUANTITY']\n",
    "df_transaction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Campaign analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_campaign_desc = pd.read_csv('dunnhumby/campaign_desc.csv')\n",
    "df_campaign_table = pd.read_csv('dunnhumby/campaign_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_campaign_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_campaign_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many campaigns we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of campaign: ', len(df_campaign_desc.CAMPAIGN))\n",
    "print('Unique description: ', df_campaign_desc.DESCRIPTION.sort_values().unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add the duration of each campaign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_campaign_desc['DURATION'] = df_campaign_desc['END_DAY'] - df_campaign_desc['START_DAY'] \n",
    "df_campaign_desc.sort_values(by = ['DESCRIPTION', 'DURATION']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each type of campaign, we compute some basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for camp in ['TypeA', 'TypeB', 'TypeC']:\n",
    "    print('Campaigns of %s range between %d and %d days' %(camp, df_campaign_desc[df_campaign_desc.DESCRIPTION == camp].DURATION.min(),\n",
    "                                                     df_campaign_desc[df_campaign_desc.DESCRIPTION == camp].DURATION.max()))\n",
    "    print('with a mean duration of %.2f days and a median duration of %.2f days.' \n",
    "            %(df_campaign_desc[df_campaign_desc.DESCRIPTION == camp].DURATION.mean(),\n",
    "              df_campaign_desc[df_campaign_desc.DESCRIPTION == camp].DURATION.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the different campaigns over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the datas per campaign type for better visualization\n",
    "beginA = df_campaign_desc[df_campaign_desc.DESCRIPTION == 'TypeA']['START_DAY'].values\n",
    "endA =   df_campaign_desc[df_campaign_desc.DESCRIPTION == 'TypeA']['END_DAY'].values\n",
    "beginB = df_campaign_desc[df_campaign_desc.DESCRIPTION == 'TypeB']['START_DAY'].values\n",
    "endB =   df_campaign_desc[df_campaign_desc.DESCRIPTION == 'TypeB']['END_DAY'].values\n",
    "beginC = df_campaign_desc[df_campaign_desc.DESCRIPTION == 'TypeC']['START_DAY'].values\n",
    "endC =   df_campaign_desc[df_campaign_desc.DESCRIPTION == 'TypeC']['END_DAY'].values\n",
    "\n",
    "#Plot the timespan of each campaign (note the +1 to match the indexes starting at 0 with the campaign numbers starting at 1)\n",
    "plt.barh(df_campaign_desc[df_campaign_desc.DESCRIPTION == 'TypeA'].index.values + 1,  endA-beginA, left=beginA, \n",
    "         color = 'red', label = 'TypeA')\n",
    "plt.barh(df_campaign_desc[df_campaign_desc.DESCRIPTION == 'TypeB'].index.values + 1,  endB-beginB, left=beginB, \n",
    "         color = 'blue', label = 'TypeB')\n",
    "plt.barh(df_campaign_desc[df_campaign_desc.DESCRIPTION == 'TypeC'].index.values + 1,  endC-beginC, left=beginC, \n",
    "         color = 'green', label = 'TypeC')\n",
    "\n",
    "#Add title & legend\n",
    "plt.title('Timespan of each campaign')\n",
    "plt.ylabel('Campaign')\n",
    "plt.yticks(df_campaign_desc.index + 1)\n",
    "plt.xlabel('Time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's observe the distribution of the number of campaigns the household have benefited from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = df_campaign_table.groupby(by = 'household_key').CAMPAIGN.count().max()\n",
    "df_campaign_table.groupby(by = 'household_key').CAMPAIGN.count().hist(bins = nbins)\n",
    "plt.title('Distribution of the number of campaigns per household')\n",
    "plt.xlabel('Number of campaigns')\n",
    "plt.ylabel('Number of households')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also print some basic statistics on the number of campaigns each household has benefited from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean number of campaigns:', df_campaign_table.groupby(by = 'household_key').CAMPAIGN.count().mean())\n",
    "print('Median number of campaigns:', df_campaign_table.groupby(by = 'household_key').CAMPAIGN.count().median())\n",
    "print('Max number of campaigns:', df_campaign_table.groupby(by = 'household_key').CAMPAIGN.count().max())\n",
    "print('25% of the households have benefited from', df_campaign_table.groupby(by = 'household_key').CAMPAIGN.count().quantile(q = 0.25),\n",
    "      'campaigns or less.')\n",
    "print('75% of the households have benefited from', df_campaign_table.groupby(by = 'household_key').CAMPAIGN.count().quantile(q = 0.75),\n",
    "      'campaigns or less.')\n",
    "print('95% of the households have benefited from', df_campaign_table.groupby(by = 'household_key').CAMPAIGN.count().quantile(q = 0.95),\n",
    "      'campaigns or less.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now move to more advanced analysis. Let's start by combining this data with the coupon data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_campaign_desc.sort_values(by = 'CAMPAIGN', inplace = True)\n",
    "df_campaign_desc.set_index(keys = 'CAMPAIGN', drop = True, inplace = True)\n",
    "df_campaign_desc['DISTRIBUTED'] = df_coupon.groupby(by = 'CAMPAIGN').REDEEMED.count() #Number of coupons distributed\n",
    "df_campaign_desc['REDEEMED'] = df_coupon[~df_coupon['REDEEMED']].groupby(by = 'CAMPAIGN').REDEEMED.count() #Number of coupons redeemed\n",
    "df_campaign_desc.fillna(0, inplace = True) \n",
    "df_campaign_desc['BENEFICIARY'] = df_campaign_table.groupby(by = 'CAMPAIGN').DESCRIPTION.count() #Number of beneficiary households\n",
    "df_campaign_desc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's observe these results in a bar plot. For each campaign we plot the amount of coupon distributed and redeemed, and we add the type of the campaign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set width of bar\n",
    "barWidth = 0.4\n",
    " \n",
    "# set height of bar\n",
    "coupon_distributed = df_campaign_desc['DISTRIBUTED']\n",
    "coupon_redeemed = df_campaign_desc['REDEEMED']\n",
    " \n",
    "# Set position of bar on X axis\n",
    "r = np.arange(len(coupon_distributed)+1)\n",
    "r1 = [x - barWidth/2 for x in r[1:]]\n",
    "r2 = [x + barWidth/2 for x in r[1:]]\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(r1, coupon_distributed, width=barWidth, edgecolor='white', label='Distributed coupon')\n",
    "plt.bar(r2, coupon_redeemed, width=barWidth, edgecolor='white', label='Redeemed coupon')\n",
    "plt.yscale('log') #Better visualizations because very different amounts of coupon between campaign\n",
    " \n",
    "# Attach a text label above each bar in *bars*, displaying the campaign type\n",
    "type_c = df_campaign_desc.DESCRIPTION.values\n",
    "for i in range(len(coupon_distributed.values)):    \n",
    "    plt.annotate('{}'.format(type_c[i]),\n",
    "                xy=(r[i+1], coupon_distributed.values[i]),\n",
    "                xytext=(0, 3),  # 3 points vertical offset\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom',\n",
    "                fontweight = 'bold',\n",
    "                fontsize = 8)\n",
    "  \n",
    "    \n",
    "# Add title and legend\n",
    "plt.title('Amount of coupon per campaign')\n",
    "plt.xlabel('Campaign')\n",
    "plt.xticks(df_campaign_desc.index)\n",
    "plt.ylabel('Amount of coupon')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the difference between the amount of coupon distributed and redeemed differs a lot from one campaign to another. It goes from cases where it is nearly null (such as campaign 1) to extreme cases where no coupons were redeemed (such as in campaigns 6, 15 and 24). To understand what happened here, we will need to inspect more precisely each campaign and join our results with data about the products and the transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do some further analysis, we will create a function *products_categories()* taking the number of a campaign and plotting the repartition of products for which coupons were offered based on the categories previously defined. It will also return this repartition as a dictionary with the proportion of each category as values and the categories as keys. A parameter *show_plot* will enable to show or not the plot (if only the proportions are needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['Meat', 'Seafood', 'Sweet snacks', 'Fruits', 'Vegetables', 'Veg animal', 'Beverage', 'Condiments', 'Carbs', 'Meals', 'Other']\n",
    "df_list = (df_meat, df_seafood, df_sweets_snack, df_fruits, df_vegetable, \n",
    "           df_veg_animal, df_beverage, df_condiments, df_carbs, df_meals, df_left)\n",
    "\n",
    "def products_categories(num_camp, show_plot = False):\n",
    "    proportions = dict.fromkeys(categories)\n",
    "    \n",
    "    #Compute the number of coupons in each category\n",
    "    for categ,df in enumerate(df_list):\n",
    "        #Check if coupon of a category are given for a specific campaign, otherwise simply puts 0 coupons\n",
    "        if num_camp in df.merge(df_coupon, on = 'PRODUCT_ID').groupby(by = 'CAMPAIGN').count().index:\n",
    "            proportions[categories[categ]] = df.merge(df_coupon, on = 'PRODUCT_ID').groupby(by = 'CAMPAIGN').count().loc[num_camp][1]\n",
    "        else:\n",
    "            proportions[categories[categ]] = 0\n",
    "        \n",
    "    '''    \n",
    "    proportions['Meat'] = df_meat.merge(df_coupon, on = 'PRODUCT_ID').groupby(by = 'CAMPAIGN').count().loc[num_camp,1]\n",
    "    proportions['Seafood'] = df_seafood.merge(df_coupon, on = 'PRODUCT_ID').groupby(by = 'CAMPAIGN').count().loc[num_camp,1]\n",
    "    proportions['Sweet snacks'] = df_sweets_snack.merge(df_coupon, on = 'PRODUCT_ID').groupby(by = 'CAMPAIGN').count().loc[num_camp,1]\n",
    "    proportions['Fruits'] = df_fruits.merge(df_coupon, on = 'PRODUCT_ID').groupby(by = 'CAMPAIGN').count().loc[num_camp,1]\n",
    "    proportions['Vegetables'] = df_vegetable.merge(df_coupon, on = 'PRODUCT_ID').groupby(by = 'CAMPAIGN').count().loc[num_camp,1]\n",
    "    proportions['Veg animal'] = df_veg_animal.merge(df_coupon, on = 'PRODUCT_ID').groupby(by = 'CAMPAIGN').count().loc[num_camp,1]\n",
    "    proportions['Beverage'] = df_beverage.merge(df_coupon, on = 'PRODUCT_ID').groupby(by = 'CAMPAIGN').count().loc[num_camp,1]\n",
    "    proportions['Condiments'] = df_condiments.merge(df_coupon, on = 'PRODUCT_ID').groupby(by = 'CAMPAIGN').count().loc[num_camp,1]\n",
    "    proportions['Carbs'] = df_carbs.merge(df_coupon, on = 'PRODUCT_ID').groupby(by = 'CAMPAIGN').count().loc[num_camp,1]\n",
    "    proportions['Meals'] = df_meals.merge(df_coupon, on = 'PRODUCT_ID').groupby(by = 'CAMPAIGN').count().loc[num_camp,1]\n",
    "    proportions['Other'] = df_left.merge(df_coupon, on = 'PRODUCT_ID').groupby(by = 'CAMPAIGN').count().loc[num_camp,1]\n",
    "    '''\n",
    "    \n",
    "    #Compute the proportion as percentage\n",
    "    total = 0\n",
    "    for i in proportions.values(): \n",
    "           total += i \n",
    "    for key in proportions.keys():\n",
    "        proportions[key] = 100*proportions[key]/total\n",
    "    \n",
    "    #Plot the repartitions of products for which coupons were offered\n",
    "    if show_plot:\n",
    "        plt.bar(range(len(proportions)), list(proportions.values()), align='center')\n",
    "        plt.xticks(range(len(proportions)), list(proportions.keys()))\n",
    "        plt.title('Proportions of coupons distributed per category during campaign ' + str(num_camp))\n",
    "        plt.xlabel('Categories')\n",
    "        plt.ylabel('Proportion of coupons [%]')\n",
    "    \n",
    "    return proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the coupons distributed are spread over the different categories for campaign 4 for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_categories(4, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see this campaign was mainly about sweet snacks.\n",
    "\n",
    "Let's now take a more overall view, across all campaign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Food and Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_trans = pd.merge(df_food, df_transaction, on='PRODUCT_ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_households = len(df_food_trans[\"household_key\"].unique())\n",
    "number_households"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check what percentile of the households did not buy meat and seafood products at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meat_seafood = df_meat.append(df_seafood)\n",
    "df_meat_seafood.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meat_seafood_trans = pd.merge(df_meat_seafood, df_transaction, on='PRODUCT_ID', how='left')\n",
    "number_household_meat_seafood = len(df_meat_seafood_trans[\"household_key\"].unique())\n",
    "print(\"Number of households who did not purchased any meat or seafood: % d\" %(number_households-number_household_meat_seafood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_meat_sea = df_meat_seafood_trans.groupby(\"WEEK_NO\").count()[\"PRODUCT_ID\"]\n",
    "weekly_trans = df_food_trans.groupby(\"WEEK_NO\").count()[\"PRODUCT_ID\"]\n",
    "plt.plot(weekly_meat_sea)\n",
    "plt.xlabel(\"Week\")\n",
    "plt.ylabel(\"Number of Meat and Seafood Transactions\")\n",
    "plt.title(\"Meat and Seafood Transactions [Weekly]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall there is no upwards or downwards trend of meat and seafood transactions. But it is weird that the meat and seafood transactions rose rapidly in the first few weeks. It is likely that in the beginning not all transactions were caught. We take a look at the relation between the number of transactions and the number of meat and seafood transactions. If the rise in the beginning is only due to the fact that not all transactions were recorded, then the relation should be linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(weekly_trans, weekly_meat_sea)\n",
    "plt.xlabel(\"Number of Transactions\")\n",
    "plt.ylabel(\"Number of Meat and Seafood Transactions\")\n",
    "plt.title(\"Meat and Seafood Transaction in Relation to overall Number of Transactions [Weekly]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relation is indeed linear.\n",
    "\n",
    "Next we take a look at the number of households which weekly buy meat or seafood products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_meat_seafood_trans.groupby(\"WEEK_NO\")[\"household_key\"].nunique())\n",
    "plt.xlabel(\"Week\")\n",
    "plt.ylabel(\"Number of Households that purchased Meat or Seafood\")\n",
    "plt.title(\"Households that purchased Meat and Seafood Transactions [Weekly]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number again stays relatively stable at around 800-900. That is surprising, because the number of households which did purchase a meat product in the two years is 2475.\n",
    "\n",
    "Let's check the number of households, which go vegetarian in a week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_vege = df_food_trans.groupby(\"WEEK_NO\")[\"household_key\"].nunique()-df_meat_seafood_trans.groupby(\"WEEK_NO\")[\"household_key\"].nunique()\n",
    "plt.plot(weekly_vege)\n",
    "plt.xlabel(\"Week\")\n",
    "plt.ylabel(\"Number of Households that purchased Meat or Seafood\")\n",
    "plt.title(\"Relation of overall households and households that bought meat or seafood [Weekly]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly the number is super high considering that almost all households do not live completely vegetarian. Lets check the frequency of the meat and seafood purchases of all households."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_purchase = df_meat_seafood_trans.groupby(\"household_key\").count()[\"PRODUCT_ID\"]\n",
    "print(house_purchase)\n",
    "plt.hist(weekly_house_purchase, bins=50)\n",
    "plt.xlabel(\"Number of meat and seafood transactions\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histrogram for Meat and SEAFOOD transaction in a household\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_purchase.sort_values().head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada] *",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
